import os
import sys
import time
import logging
from dotenv import load_dotenv
from database import Database
from analyzer import AIAnalyzer
from notifier import Notifier

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("analyze.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("Analyzer")

class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    def __init__(self, requests_per_minute=15):
        self.rpm = requests_per_minute
        self.interval = 60.0 / requests_per_minute
        self.last_request = 0
    
    def wait(self):
        """ç­‰å¾…ç›´åˆ°å¯ä»¥å‘é€ä¸‹ä¸€ä¸ªè¯·æ±‚"""
        elapsed = time.time() - self.last_request
        if elapsed < self.interval:
            wait_time = self.interval - elapsed
            logger.info(f"Rate limiting: waiting {wait_time:.2f}s...")
            time.sleep(wait_time)
        self.last_request = time.time()

def is_valid_post(pid, content, author, section_name):
    """éªŒè¯å¸–å­æ•°æ®æ˜¯å¦æœ‰æ•ˆ"""
    # è¿‡æ»¤æ— æ•ˆ ID
    if not pid or pid == "file_None" or "None" in str(pid):
        logger.warning(f"Invalid post ID: {pid}")
        return False
    
    # è¿‡æ»¤ç©ºå†…å®¹æˆ–å†…å®¹è¿‡çŸ­
    if not content or len(content.strip()) < 50:
        logger.warning(f"Content too short for post {pid}: {len(content) if content else 0} chars")
        return False
    
    # è¿‡æ»¤æ–‡ä»¶åˆ†äº«é¡µé¢ï¼ˆé€šå¸¸å†…å®¹å¾ˆçŸ­ä¸”æ— å®é™…æŠ•èµ„ä¿¡æ¯ï¼‰
    if section_name == "æ–‡ä»¶åˆ†äº«" and len(content) < 100:
        logger.warning(f"Skipping file sharing post {pid} with short content")
        return False
    
    # è¿‡æ»¤æœªçŸ¥ä½œè€…ä¸”å†…å®¹è¿‡çŸ­çš„å¸–å­
    if author == "Unknown" and len(content) < 200:
        logger.warning(f"Skipping unknown author post {pid} with short content")
        return False
    
    return True

def main():
    # é…ç½®
    ai_api_key = os.getenv("AI_API_KEY")
    ai_base_url = os.getenv("AI_BASE_URL", "https://api.deepseek.com")
    ai_provider = os.getenv("AI_PROVIDER", "openai")
    gemini_key = os.getenv("GEMINI_API_KEY")
    gemini_model = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")
    star_owner_name = os.getenv("STAR_OWNER_NAME")
    
    ding_url = os.getenv("DINGTALK_WEBHOOK")
    ding_secret = os.getenv("DINGTALK_SECRET")
    
    # é€Ÿç‡æ§åˆ¶é…ç½®
    max_posts_per_run = int(os.getenv("MAX_POSTS_PER_RUN", "10"))
    requests_per_minute = int(os.getenv("AI_REQUESTS_PER_MINUTE", "10"))
    
    # åˆå§‹åŒ–
    db = Database()
    analyzer = AIAnalyzer(
        ai_api_key, 
        ai_base_url, 
        provider=ai_provider, 
        gemini_key=gemini_key, 
        gemini_model=gemini_model,
        star_owner_name=star_owner_name
    )
    notifier = Notifier(ding_url, ding_secret)
    rate_limiter = RateLimiter(requests_per_minute=requests_per_minute)
    
    # è·å–æœªåˆ†æå¸–å­æ•°é‡
    total_unanalyzed = db.get_unanalyzed_count()
    logger.info(f"DEBUG: Total unanalyzed posts returned by DB: {total_unanalyzed}")
    
    if total_unanalyzed == 0:
        logger.info("No posts to analyze. Exiting.")
        return 0
    
    # è·å–æœ¬æ¬¡è¦åˆ†æçš„å¸–å­(é™åˆ¶æ•°é‡)
    logger.info(f"DEBUG: Attempting to fetch max {max_posts_per_run} posts...")
    unanalyzed = db.get_unanalyzed_posts(limit=max_posts_per_run)
    logger.info(f"DEBUG: Fetched {len(unanalyzed)} posts for analysis.")
    logger.info(f"Analyzing {len(unanalyzed)} posts (max: {max_posts_per_run})...")
    
    # é€ä¸ªåˆ†æ
    success_count = 0
    valuable_count = 0
    
    for idx, (pid, content, url, author, create_time, section_name) in enumerate(unanalyzed, 1):
        logger.info(f"[{idx}/{len(unanalyzed)}] Processing post {pid}...")
        
        # æ•°æ®éªŒè¯
        if not is_valid_post(pid, content, author, section_name):
            logger.info(f"  âŠ˜ Skipped invalid post {pid}")
            # æ ‡è®°ä¸ºå·²åˆ†æï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
            db.update_analysis(pid, "æ— æ•ˆæ•°æ®", "è·³è¿‡", "æ•°æ®éªŒè¯å¤±è´¥", "æ­¤å¸–å­æ•°æ®æ— æ•ˆï¼Œå·²è·³è¿‡åˆ†æ")
            continue
        
        logger.info(f"  âœ“ Post validation passed")
        logger.info(f"  Post ID: {pid}")
        logger.info(f"  Author: {author}")
        logger.info(f"  Section: {section_name}")
        logger.info(f"  URL: {url}")
        logger.info(f"  Content length: {len(content)} chars")
        
        # Log content preview
        content_preview = content[:300] + "..." if len(content) > 300 else content
        logger.debug(f"  Content preview: {content_preview}")
        
        try:
            # é€Ÿç‡é™åˆ¶
            rate_limiter.wait()
            
            # AIåˆ†æ
            logger.info(f"  Sending to AI analyzer...")
            analysis = analyzer.analyze_post(content)
            
            if analysis:
                logger.info(f"  âœ“ Analysis successful!")
                logger.info(f"    - is_valuable: {analysis.get('is_valuable')}")
                logger.info(f"    - ticker: {analysis.get('ticker', 'æ— ')}")
                logger.info(f"    - suggestion: {analysis.get('suggestion', 'æ— ')}")
                logger.info(f"    - logic: {analysis.get('logic', 'æ— ')[:100]}..." if len(analysis.get('logic', '')) > 100 else f"    - logic: {analysis.get('logic', 'æ— ')}")
                logger.info(f"    - ai_summary: {analysis.get('ai_summary', 'æ— ')}")
                
                # æ›´æ–°æ•°æ®åº“
                db.update_analysis(
                    pid,
                    analysis.get('ticker', 'æ— '),
                    analysis.get('suggestion', 'æ— '),
                    analysis.get('logic', 'æ— '),
                    analysis.get('ai_summary', 'æ— ')
                )
                success_count += 1
                logger.info(f"  âœ“ Database updated for post {pid}")
                
                # å‘é€é€šçŸ¥(å¦‚æœæœ‰ä»·å€¼)
                if analysis.get('is_valuable'):
                    valuable_count += 1
                    logger.info(f"  ğŸ“¢ Valuable info found! Sending DingTalk notification...")
                    notifier.notify_investment_report(
                        url,
                        analysis.get('ticker'),
                        analysis.get('suggestion'),
                        analysis.get('logic'),
                        analysis.get('ai_summary'),
                        author=author,
                        create_time=create_time,
                        section_name=section_name
                    )
                    logger.info(f"  âœ“ Notification sent")
                else:
                    logger.info(f"  â„¹ Post {pid} analyzed but not valuable (no notification sent)")
            else:
                logger.warning(f"  âœ— Failed to analyze post {pid} - analyzer returned None")
                
        except Exception as e:
            logger.error(f"Error analyzing post {pid}: {e}")
            continue
    
    # ç»Ÿè®¡ä¿¡æ¯
    remaining = total_unanalyzed - success_count
    logger.info(f"Analysis complete. Processed: {success_count}/{len(unanalyzed)}, Valuable: {valuable_count}, Remaining: {remaining}")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
